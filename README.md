# ðŸ¤– AI Agent Chatbot

A modern full-stack **AI Agent Chatbot** built with **FastAPI (Python)** backend, **React + Tailwind CSS** frontend, and **LangGraph + LLMs** (OpenAI / Groq / Tavily) to enable intelligent conversation workflows.

- ### Demo Preview
<p align="center">
  <img src="https://github.com/CodeWithAnji/AI-Agent_Chatbot/blob/008ef5b7a6da8341cbf59f7f8b20b6cc6b062fb4/screenshot.png" width="600" height="1000" />
</p>

## Features
- ðŸŒ Full-stack AI chatbot with modern UI
- ðŸ”„ LangGraph StateGraph workflow implementation
- ðŸ¤– Multi-LLM support (OpenAI / Groq / Tavily Search)
- ðŸ“¡ FastAPI backend with REST API endpoint
- ðŸ’¬ Infinite scroll chat interface
- ðŸŽ¨ Modern responsive UI using Tailwind CSS
- ðŸ“ Input textbox fixed at bottom, chat scrolls above
- ðŸ”‘ Secure API key handling using `.env` (not pushed to GitHub)
- ðŸ–¥ Responsive layout for desktop & mobile

## ðŸ— Tech Stack

### **Frontend**
- React.js
- Tailwind CSS
- Axios

### **Backend**
- FastAPI (Python)
- LangGraph + LangChain
- Uvicorn
- Groq Llama 3.1
- OpenAI GPT-4o mini
- Tavily Search

##  Environment Variables

Create a file `.env` inside `backend/`
OPENAI_API_KEY=your_openai_key
GROQ_API_KEY=your_groq_key
TAVILY_API_KEY=your_tavily_key

> âš  Never commit `.env` to GitHub â€” already added to `.gitignore`

##  How It Works
1. User selects LLM (OpenAI / Groq)
2. Sends prompt â†’ Backend FastAPI `/chat` endpoint
3. LangGraph agent executes model & generates response
4. Result streamed back and displayed in UI

## â–¶ Run Locally

### **Backend**

cd backend

pip install -r requirements.txt

uvicorn app.main:app --reload

### **Frontend**

cd frontend

npm install

npm run dev
